<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  

  

  <meta name="google-site-verification" content="iwQxTRUwaNIwoOR54fLWzRin2YR5yV9Ayp3rvM4FPW0" />
  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-130937805-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-130937805-1');
</script>


  <title>logistic | THIS IS NOT A TECH BLOG</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="패스트캠퍼스 데이터사이언스 스쿨 강의노트를 참고했습니다 확률적 모형 로지스틱 회귀 모형은 “확률적(probabilistic)”, “판별(discriminative)” 모형 중 하나이다. 확률적 판별 모형은, 주어진 데이터에 대해 각 카테고리(혹은 클래스)가 정답일 조건부 확률을 계산하기 때문에 확률적 모형에 속한다. 확률적 모형은 독립변수 $x$가 주어졌을">
<meta name="keywords" content="machinelearning, algorithm, logistic, concept, theory, probabilistic, discriminative, 머신러닝, 알고리즘, 로지스틱, 로지스틱 회귀분석, 개념, 이해, 설명">
<meta property="og:type" content="article">
<meta property="og:title" content="logistic">
<meta property="og:url" content="https://seokyeongheo.github.io/2018/12/13/logistic/index.html">
<meta property="og:site_name" content="THIS IS NOT A TECH BLOG">
<meta property="og:description" content="패스트캠퍼스 데이터사이언스 스쿨 강의노트를 참고했습니다 확률적 모형 로지스틱 회귀 모형은 “확률적(probabilistic)”, “판별(discriminative)” 모형 중 하나이다. 확률적 판별 모형은, 주어진 데이터에 대해 각 카테고리(혹은 클래스)가 정답일 조건부 확률을 계산하기 때문에 확률적 모형에 속한다. 확률적 모형은 독립변수 $x$가 주어졌을">
<meta property="og:locale" content="KOREAN">
<meta property="og:updated_time" content="2018-12-17T09:04:26.571Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="logistic">
<meta name="twitter:description" content="패스트캠퍼스 데이터사이언스 스쿨 강의노트를 참고했습니다 확률적 모형 로지스틱 회귀 모형은 “확률적(probabilistic)”, “판별(discriminative)” 모형 중 하나이다. 확률적 판별 모형은, 주어진 데이터에 대해 각 카테고리(혹은 클래스)가 정답일 조건부 확률을 계산하기 때문에 확률적 모형에 속한다. 확률적 모형은 독립변수 $x$가 주어졌을">
  
    <link rel="alternate" href="/atom.xml" title="THIS IS NOT A TECH BLOG" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">THIS IS NOT A TECH BLOG</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://seokyeongheo.github.io"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-logistic" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/12/13/logistic/" class="article-date">
  <time datetime="2018-12-13T03:02:33.000Z" itemprop="datePublished">2018-12-13</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      logistic
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h4 id="패스트캠퍼스-데이터사이언스-스쿨-강의노트를-참고했습니다"><a href="#패스트캠퍼스-데이터사이언스-스쿨-강의노트를-참고했습니다" class="headerlink" title="패스트캠퍼스 데이터사이언스 스쿨 강의노트를 참고했습니다"></a><em>패스트캠퍼스 데이터사이언스 스쿨 강의노트를 참고했습니다</em></h4><hr>
<h3 id="확률적-모형"><a href="#확률적-모형" class="headerlink" title="확률적 모형"></a>확률적 모형</h3><ul>
<li>로지스틱 회귀 모형은 “확률적(probabilistic)”, “판별(discriminative)” 모형 중 하나이다.</li>
<li>확률적 판별 모형은, 주어진 데이터에 대해 각 카테고리(혹은 클래스)가 정답일 조건부 확률을 계산하기 때문에 확률적 모형에 속한다.</li>
<li>확률적 모형은 독립변수 $x$가 주어졌을 때, 종속변수 $y$가 될 확률 $P(y = k \mid x)$를 모두 계산하고(1), 다음으로 가장 확률이 큰 클래스를 선택한다.(2)</li>
</ul>
<p>$$<br>\text{(1)     }<br>\begin{eqnarray}<br>P_1 &amp;=&amp; P(y = 1 \mid x) \<br>\vdots &amp; &amp; \vdots \<br>P_K &amp;=&amp; P(y = K \mid x)<br>\end{eqnarray}<br>$$</p>
<p>$$<br>\text{(2)     }<br>y = \arg\max_{k} P(y=k \mid x)<br>$$</p>
<ul>
<li>확률적 모형은 생성모형(generative model)과 판별모형(discriminative model)로 나뉜다.</li>
</ul>
<h3 id="확률적-판별-모형"><a href="#확률적-판별-모형" class="headerlink" title="확률적 판별 모형"></a>확률적 판별 모형</h3><ul>
<li>확률론적 판별 모형은 조건부확률 $p(y = 1 \mid x)$ 이 $x$ 에 대한 함수 $f(x)$ 로 표시될 수 있다고 가정하고 그 함수를 직접 찾아내는 방법이다.</li>
<li>단, 이 함수 $f(x)$ 는 확률이기 때문에, “0과 1사이의 실수”를 결과로 도출해야 한다.</li>
</ul>
<hr>
<h3 id="로지스틱-회귀-모형-개념"><a href="#로지스틱-회귀-모형-개념" class="headerlink" title="로지스틱 회귀 모형: 개념"></a>로지스틱 회귀 모형: 개념</h3><ol>
<li>로지스틱 회귀(logistic regression)은 독립변수의 선형 결합을 이용하여 종속변수 발생 가능성을 예측하는 알고리즘이다.</li>
<li>선형 회귀처럼, 독립변수로 종속변수를 설명한다. 그러나 선형 회귀와 다르게 종속변수가 범주형 데이터일 때 주로 사용하기 때문에 일종의 분류(classification) 알고리즘이라고도 할 수 있다.</li>
<li>종속변수가 두 개 이상의 범주인 경우, 다항 로지스틱 회귀(multinomial logistic regression) 또는 분화 로지스틱 회귀(polytomous logistic regression) 알고리즘을 사용한다.</li>
</ol>
<h3 id="로지스틱-회귀-모형-원리"><a href="#로지스틱-회귀-모형-원리" class="headerlink" title="로지스틱 회귀 모형: 원리"></a>로지스틱 회귀 모형: 원리</h3><ol>
<li>종속변수가 베르누이 분포를 따른다고 가정하고, 모수 $\mu$를 추정한다.</li>
<li>종속변수가 베르누이 분포를 따른다면, 베르누이 분포의 모수 $\mu$는 0과 1 사이 실수이다. 왜냐하면 베르누이 확률변수의 모수 $\mu$는 1이 나올 확률을 의미하는데, 확률은 0과 1 사이의 사이의 실수이기 때문이다.</li>
<li>그런데 모수 $\mu$을 추정하기 위한, 표본 데이터 $y_1, \ldots, y_N$은 0과 1 사이의 실수가 아닌 음의 무한대와 양의 무한대 사이의 실수, 즉 모든 실수이다.</li>
<li>그러므로 모든 실수로 나오는 종속변수가, 0과 1 사이의 베르누이 분포를 띄는 종속변수로 나오도록 하기 위해서는 아래와 같은 일련의 과정이 필요하다.</li>
</ol>
<pre><code>(i) odds ratio를 활용하여, 0과 1 사이의 실수를 0과 양의 무한대 사이의 실수로 변환한다.
</code></pre><p>$\text{odds ratio} = \dfrac{\mu}{1-\mu}$</p>
<pre><code>(ii) odds ratio를 로그 변환하여, 로지트 함수(Logit function)를 만든다.
</code></pre><p>$z = \text{logit}(\text{odds ratio}) = \log \left(\dfrac{\mu}{1-\mu}\right)$</p>
<pre><code>(iii) 로지트 함수의 역함수, 로지스틱 함수(logistic function)을 만든다. 로지스틱 함수는, 음의 무한대에서 양의 무한대까지의 실수를 0부터 1사이의 실수로 변환한다.
</code></pre><p>$\text{logitstic}(z) = \mu(z) = \dfrac{1}{1+\exp{(-z)}}$</p>
<p>5.LL : 로지스틱 모형은 비선형 모형이기 때문에 모수 $w$ 를 추정하기 위해서는, MLE를 활용해야 한다. 아래는 MLE에서, LL(Log Likelihood).</p>
<p>\begin{eqnarray}<br>\text{LL}<br>&amp;=&amp; \log \prod_{i=1}^N \mu(x_i;w)^{y_i} (1-\mu(x_i;w))^{1-y_i} \<br>&amp;=&amp; \sum_{i=1}^N \left( y_i \log\mu(x_i;w) +  (1-y_i)\log(1-\mu(x_i;w)) \right) \<br>&amp;=&amp; \sum_{i=1}^N \left( y_i \log\left(\dfrac{1}{1 + \exp{(-w^Tx_i)}}\right) + (1-y_i)\log\left(\dfrac{\exp{(-w^Tx_i)}}{1 + \exp{(-w^Tx_i)}}\right) \right) \<br>\end{eqnarray}</p>
<p>6.LL을 최대로 하는 $w$ 를 구하기 위해서 아래와 같이 미분을 하고, 두 식을 정리하면, 아래와 같은 결과가 나온다</p>
<p>$$<br>\dfrac{\partial\text{LL}}{\partial w}  = \sum_{i=1}^N \dfrac{\partial\text{LL}}{\partial \mu(x_i;w)} \dfrac{\partial\mu(x_i;w)}{\partial w}<br>$$</p>
<p>\begin{eqnarray}<br>\dfrac{\partial \text{LL}}{\partial w}<br>&amp;=&amp; \sum_{i=1}^N \left( y_i \dfrac{1}{\mu(x_i;w)} - (1-y_i)\dfrac{1}{1-\mu(x_i;w)} \right) \mu(x_i;w)(1-\mu(x_i;w)) x_i   \<br>&amp;=&amp; \sum_{i=1}^N \big( y_i (1-\mu(x_i;w)) - (1-y_i)\mu(x_i;w)  \big)  x_i \<br>&amp;=&amp; \sum_{i=1}^N \big( y_i  - \mu(x_i;w) \big) x_i \<br>\end{eqnarray}</p>
<p>7.SGD(Steepest Gradient Descent)를 활용해서, 목적함수 $J$를 최소화하는 $w$를 구한다. 목적함수 $J$는 $-LL$이다.</p>
<p>\begin{eqnarray}<br>w_{k+1}<br>&amp;=&amp; w_{k} - \eta_k g_k \<br>&amp;=&amp; w_{k} + \eta_k \sum_{i=1}^N \big( y_i  - \mu(x_i; w_k) \big) x_i\<br>\end{eqnarray}</p>
<h3 id="로지스틱-회귀-모형-성능-측정"><a href="#로지스틱-회귀-모형-성능-측정" class="headerlink" title="로지스틱 회귀 모형: 성능 측정"></a>로지스틱 회귀 모형: 성능 측정</h3><ul>
<li>로지스틱 회귀 성능은 McFadden pseudo R square 값으로 측정한다.</li>
</ul>
<p>$$ R^2_{\text{pseudo}} = 1 - \dfrac{G^2}{G^2_0} $$</p>
<ul>
<li>$ G^2$는 deviance로, 로그 로스(log loss)라고도 하며 아래처럼 정의된다. deviance는 모형이 100% 정확한 경우 0, 모형이 성능이 나빠질 경우 값이 커진다. $G^2$ 는 현재 deviance, $G^2_0$ 는 귀무 모형으로 측정한 deviance 이다.</li>
</ul>
<p>$$ G^2 = 2\sum_{i=1}^N \left( y_i\log\dfrac{y_i}{\hat{y}_i} + (1-y_i)\log\dfrac{1-y_i}{1-\hat{y}_i} \right) $$<br>$$ G^2 = - LL $$</p>
<hr>
<h4 id="부록-모수-추정"><a href="#부록-모수-추정" class="headerlink" title="부록: 모수 추정"></a>부록: 모수 추정</h4><ol>
<li>모수 추정은 확률분포의 표본 데이터 $x_1, x_2, x_3, …, x_n$ 값은 알고 있는데, 모수를 알지 못하는 경우 활용한다.</li>
<li>모수 추정을 활용하면, 표본 데이터로 역으로 모수를 추정하고 나아가 새로운 표본 데이터를 생성할 수 있다.<ul>
<li>확률변수 : 수학적으로 확률이 정의된 “표본공간의 모든 표본”을 실수인 숫자로 바꾸는 함수. 가상의 수학 세계에 존재하는 것으로, 현실 세계의 표본(sample)을 만드는 데이터생성기 역할을 한다.</li>
</ul>
</li>
<li>모수 추정은 모멘트 방법, 최대 가능도 추정(MLE), 베이지안 추정 등 방법이 있다.</li>
</ol>
<h4 id="부록-최대-가능도-모수-추정의-원리-MLE"><a href="#부록-최대-가능도-모수-추정의-원리-MLE" class="headerlink" title="부록: 최대 가능도 모수 추정의 원리 (MLE)"></a>부록: 최대 가능도 모수 추정의 원리 (MLE)</h4><ol>
<li>최대 가능도 추정(MLE)는 표본 데이터 $x$ 에 대해 가능도를 가장 크게 하는 모수 $\theta$를 찾는 방법이다.</li>
<li>보통 확률변수 표본 수는 단수가 아닌 복수 {$x_1, x_2, \ldots, x_N$} 이므로 가능도도 복수 표본에 대한 결합 확률밀도 $p_{X_1, X_2, \cdots, X_N}(x_1, x_2, \cdots, x_N ; \theta)$ 에서 구해야 한다.</li>
<li>그런데 표본 데이터 $x_1, \ldots, x_N$ 은 확률분포에서 독립적으로 나왔으므로 결합 확률밀도함수는 아래처럼 표현한다.<br> $$ L(\theta; x_1, \ldots, x_N) = L(\theta; { x_i }<em>{i=1}^N) = \prod</em>{i=1}^N p(x_i ; \theta)$$</li>
<li>실제로 최대 가능도 추정 방법을 사용하려면, 가능도가 최대가 되는 $\theta$ 를 로그 변환하여 수치적으로 계산해야 한다. (수치적 최적화) $\hat\theta_{\text{ML}} = \arg \max_{\theta} {\text{log}} \; L(\theta; {x_i})$<ul>
<li>그 이유는 (1) 로그변환을 해도, 최대 가능도 추정의 결과(모수)가 바뀌지 않고</li>
<li>(2) 로그변환을 하면, 결합 확률밀도함수가 함수의 곱에서 덧셈으로 바뀌어 연산이 쉬워지기 때문이다.</li>
</ul>
</li>
</ol>
<h4 id="부록-베르누이-분포"><a href="#부록-베르누이-분포" class="headerlink" title="부록: 베르누이 분포"></a>부록: 베르누이 분포</h4><ol>
<li>베르누이 확률변수는 베루누이 확률변수의 결과를 실수 0 또는 실수 1로 바꾼 것이다.</li>
<li><p>두 가지 값 - 0, 1 - 중 하나만 가질 수 있으므로 이산확률변수라고도 한다.</p>
<p> $$\text{Bern}(x;\mu) =<br>\begin{cases}<br>\mu   &amp; \text{if }x=1, \<br>1-\mu &amp; \text{if }x=0<br>\end{cases}$$</p>
</li>
<li><p>베르누이 확률변수는 1이 나올 확률을 의미하는 $\mu$라는 모수(parameter)를 가진다.</p>
</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://seokyeongheo.github.io/2018/12/13/logistic/" data-id="cjps3g98u0001yqa5406x12gi" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/machinelearning-algorithm-logistic-concept-theory-probabilistic-discriminative-머신러닝-알고리즘-로지스틱-로지스틱-회귀분석-개념-이해-설명/">machinelearning, algorithm, logistic, concept, theory, probabilistic, discriminative, 머신러닝, 알고리즘, 로지스틱, 로지스틱 회귀분석, 개념, 이해, 설명</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2018/12/13/qdalda/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          qdalda
        
      </div>
    </a>
  
  
    <a href="/2018/12/12/naivebayes/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">naivebayes</div>
    </a>
  
</nav>

  
</article>

</section>
        
      </div>
      <footer id="footer">
  
    <aside id="sidebar" class="outer">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/machinelearning-algorithm-logistic-concept-theory-probabilistic-discriminative-머신러닝-알고리즘-로지스틱-로지스틱-회귀분석-개념-이해-설명/">machinelearning, algorithm, logistic, concept, theory, probabilistic, discriminative, 머신러닝, 알고리즘, 로지스틱, 로지스틱 회귀분석, 개념, 이해, 설명</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/machinelearning-algorithm-머신러닝-알고리즘-Korean-tutorial-concept-theory-classification-tree-개념-이해-설명/">machinelearning, algorithm, 머신러닝, 알고리즘, Korean, tutorial, concept, theory, classification, tree, 개념, 이해, 설명</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/machinelearning-algorithm-머신러닝-알고리즘-QDA-LDA/">machinelearning, algorithm, 머신러닝, 알고리즘, QDA, LDA</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/naivebayes-machinelearning-korean-tutorial/">naivebayes, machinelearning, korean, tutorial</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/데이터사이언스-스터디-프로젝트-준비-흥미-패러다임-공부법-대비-패스트캠퍼스/">데이터사이언스, 스터디, 프로젝트, 준비, 흥미, 패러다임, 공부법, 대비, 패스트캠퍼스</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2018/12/17/decisiontree/">결정 나무 (Decision Tree)</a>
          </li>
        
          <li>
            <a href="/2018/12/13/qdalda/">qdalda</a>
          </li>
        
          <li>
            <a href="/2018/12/13/logistic/">logistic</a>
          </li>
        
          <li>
            <a href="/2018/12/12/naivebayes/">naivebayes</a>
          </li>
        
          <li>
            <a href="/2018/09/06/linear-algebra-2/">linear-algebra-2</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2018 quartz<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>